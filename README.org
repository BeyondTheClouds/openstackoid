#+TITLE: OpenStackoÃ¯d

/Make your OpenStacks Collaborative/

This PoC aims at making several independent OpenStack instances
collaborative. The main idea consists in extending the OpenStack CLI
to define the collaboration process. A dedicated option, called
~--os-scope~, specifies which services (e.g., compute, image,
identity, ...) of which OpenStack instance (e.g., InstanceOne,
InstanceTwo, ...) an OpenStack is made of to perform the CLI request.
For instance, the provisioning of a VM in InstanceOne with an image in
InstanceTwo looks like as follows:

: openstack server create my-vm --flavor m1.tiny --image cirros \
:   --os-scope '{"compute": "InstanceOne", "image": "InstanceTwo"}'

This approach enables the segregation of the infrastructure into
distinct areas. It removes the relying on a single control plane and
thus, resolves network partitioning and scalability challenges in most
cases.

To get more insight, read the [[#how-it-works][how it works]] section or [[#try-it][try it]] by
yourself.
# Also read our [[https://beyondtheclouds.github.io/blog/][blog post]]


* Table of Contents                                                  :TOC@2@gh:
- [[#try-it][Try it]]
- [[#limitation][Limitation]]
- [[#how-it-works][How it works]]
  - [[#generating-the-haproxy-configuration-file][Generating the HAProxy configuration file]]
  - [[#scope-should-follow-the-workflow][Scope should follow the workflow]]
- [[#setup][Setup]]
  - [[#openstack-deployment-with-devstack][OpenStack deployment with Devstack]]
  - [[#scope-interpretation][Scope interpretation]]
- [[#list-of-todos][List of TODOs]]
- [[#misc][Misc]]
  - [[#see-haproxy-log][See HAProxy log]]
- [[#acknowledgment][Acknowledgment]]

* Try it
  :PROPERTIES:
  :CUSTOM_ID: try-it
  :END:
Get the code with a git clone.
: git clone git@github.com:BeyondTheClouds/openstackoid.git -b stable/rocky --depth 1

Then starts the two OpenStack instances (require tmux and Vagrant).
: cd openstackoid; ./setup-env.sh

The previous command starts two tmux windows and launches two
OpenStack instances, each in a virtual machine, thanks to Vagrant.
After 15 to 20 minutes, the time for Devstack to deploy the two
OpenStack instances, the output may look like the following. The top
window connects to OpenStack ~InstanceOne~ and the bottom one to
~InstanceTwo~. These two instances are completely independent and
shared no services.

#+begin_example
stack@InstanceOne:~$
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$
#+end_example

From there you can issue a standard ~openstack~ command, such as
~openstack image list~. Note the difference of ~ID~.

#+begin_example
stack@InstanceOne:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 440263d5-20a7-432b-b0db-693787bd2579 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 45da7b62-163c-4c78-aac7-363cbf4627a4 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
#+end_example

Moreover, you can use the ~--os-scope~ option that tells OpenStack of
a specific instance to do something by using a service from another
instance. For example, you can tell to the ~InstanceOne~ to start a VM
by using the ~image~ service from ~InstanceTwo~ (the ~ID~ of ~image~
is the one of ~InstanceTwo~). In the scope, a service is implicitly
bound to the local instance, which prevents to explicitly specify all
services.

#+begin_example
stack@InstanceOne:~$ openstack server create my-vm \
  --os-scope '{"image": "InstanceTwo"}' \
  --image 45da7b62-163c-4c78-aac7-363cbf4627a4 \
  --flavor m1.tiny \
  --wait
+-------------------------------------+-----------------------------------------------------------------+
| Field                               | Value                                                           |
+-------------------------------------+-----------------------------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                                                          |
| ...                                 | ...                                                             |
| image                               | cirros-0.3.5-x86_64-disk (45da7b62-163c-4c78-aac7-363cbf4627a4) |
| name                                | my-vm                                                           |
| ...                                 | ...                                                             |
| status                              | ACTIVE                                                          |
| user_id                             | 2d9440f8a4d546c88d1f5b661dc6e69b                                |
+-------------------------------------+-----------------------------------------------------------------+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 45da7b62-163c-4c78-aac7-363cbf4627a4 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
#+end_example

ðŸŽ‰

* TODO Limitation
- Same project id
- Same keystone credential
- Resource of another instance should be accessible from the first one
  (e.g., image is OK, network is NOK).

* How it works
  :PROPERTIES:
  :CUSTOM_ID: how-it-works
  :END:
In brief, every OpenStack instance comes with a proxy (here HAProxy)
in front of it. In such deployment, a service (e.g., Glance API of
~InstanceOne~) is available via two addresses:
- The /Backend/ address (i.e., ~10.0.2.15/image~) that directly
  targets Glance API.
- The /Frontend/ address (i.e., ~192.168.141.245:8888/image~)
  that targets HAProxy. HAProxy then evaluates the request and, in
  most cases, forwards it to the Backend.

Here, we add a new capability to HAProxy [[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/playbooks/haproxy/lua/interpret_scope.lua.j2][that interprets]] the
~--os-scope~. Instead of forwarding the request to the local Backend,
HAProxy determines the instance of the targeted service from the scope
and URL. It then forwards the request to the local Backend only if the
current instance is equivalent to the determined one. Otherwise, it
forwards the request to the Frontend of the determined instance.

As an example, here is a sample of the HAProxy configuration on
~InstanceOne~ for the ~image~ service.

#+begin_src conf-space -n
listen http-proxy
  bind 192.168.141.245:8888           # (ref:local-front)
  http-request del-header X-Forwarded-Proto if { ssl_fc }
  use_backend %[lua.interpret_scope]  # (ref:lua-scope)

# Target concrete backend
backend InstanceOne_image_public
  server InstanceOne 10.0.2.15:80 check inter 2000 rise 2 fall 5 # (ref:local-back)

# Target HA of OS instance named InstanceTwo
backend InstanceTwo_image_public
  http-request set-header Host 192.168.141.245:8888
  server InstanceTwo 192.168.142.245:8888 check inter 2000 rise 2 fall 5 # (ref:remote-front)

# Do the same for compute, identity, ...
#+end_src

The ~lua.interpret_scope~ line [[(lua-scope)]] determines the name of the
backend based on the ~--os-scope '{"image": "InstanceTwo"}~ and URL of
the targeted service. From there, it forwards the request whether to
the local Backend ~10.0.2.15~ (l. [[(local-back)]]) or Frontend of the
remote instance ~192.168.142.245~ (l. [[(remote-front)]]).

** Generating the HAProxy configuration file
Based on a short description list of all services (see lst.
[[lst:services-desc]]), it is easy to [[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/playbooks/haproxy/haproxy.cfg.j2][generate the HAProxy configuration
file]] automatically. The description list, on the other hand, partially
comes with the next OpenStack command. The addresses of the Frontend
and Backend for all services still have to be added.

: openstack endpoint list --format json \
:   -c "Service Type" -c "Interface" -c "URL" -c "Region"

#+NAME: lst:services-desc
#+CAPTION: Services description list
#+begin_src json
{ "services" :
  [
    {
      "Service Type": "image",
      "Interface": "public",
      "URL": "192.168.141.245:8888/image",
      "Region": "InstanceOne",
      "Frontend": "192.168.141.245:8888",
      "Backend": "10.0.2.15:80"
    },
    ...
    {
      "Service Type": "image",
      "Interface": "public",
      "URL": "192.168.142.245:8888/image",
      "Region": "InstanceTwo",
      "Frontend": "192.168.142.245:8888",
      "Backend": "10.0.2.15:80"
    },
    ...
  ]
}
#+end_src

** Scope should follow the workflow
HAProxy determines from the ~--os-scope~ the address of the targeted
service. Which means, the scope has to be defined for every request
and subsequent requests. For instance, when Alice does an ~openstack
server create --os-scope ...~, the value of the ~--os-scope~ should
not only be attached to the initial ~POST /servers~ request made by
the CLI. But also, to all subsequent requests of the workflow,
including Nova request to Keystone to check Alice credentials, Nova
request to Glance to check/get the image. Glance request to Keystone
to check Alice credentials ...

A first solution is to modify the OpenStack code of all services to
ensure that, e.g., when Alice contacts Nova with a specific
~--os-scope~, then Nova propagates that ~--os-scope~ in the subsequent
requests. However, in OpenStackoid, we want to avoid as much as
possible modifications to the vanilla code.

Another naive implementation would try to implement the scope
propagation at HAProxy level -- and keep OpenStack code as it is.
Unfortunately, this doesn't work since HAPrxoy is unlikely to figure
out that, e.g., the current request from Nova to Glance comes from a
previous request from Alice to Nova with a specific ~--os-scope~.

Luckily, every OpenStack service already propagates information from
one service to another during the entire workflow of command: the
Keystone ~X-Auth-Token~ that contains Alice credentials. Here we reuse
that information to piggyback the ~--os-scope~. Then, HAProxy seeks
for the ~X-Auth-Token~, extracts the scope and finally interprets it
to forwards the request to the good instance.

* Setup
The setup is made of, but not limited to, two distinct VirtualBox VMs
with an All-in-One OpenStack inside each. The [[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/setup-env.sh][setup-env.sh]] script
starts two tmux windows and runs vagrant inside each window. Vagrant
is in charge of deploying the All-in-One OpenStack and then
configuring OpenStack to interpret the ~--os-scope~.

The [[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/Vagrantfile][Vagrantfile]] contains the description of the two All-in-One
OpenStack at its top (see ~os_confs~). The ~:name~ refers to the name
of the instance, ~:ip~ to the Frontend address (has to be accessible
by other instances), and ~:ssh~ to the port used by Vagrant for SSH
connections. Doing a ~vagrant up~ reads that configuration and starts
two Ubuntu/16.04 VMs with these characteristics. Adding a third entry
in ~os_confs~ and running ~vagrant up~ again will start a third
All-in-One OpenStack.

#+CAPTION: Configuration of OpenStack instances
#+begin_src ruby
os_confs = [
  {
    :name => "InstanceOne",
    :ip => "192.168.141.245",
    :ssh => 2141
  },
  {
    :name => "InstanceTwo",
    :ip => "192.168.142.245",
    :ssh => 2142
  }
]
#+end_src

It is also possible to start only one OpenStack instance by giving its
name after the ~vagrant up~. For instance, the following command only
starts and configures the ~InstanceOne~.

: vagrant up InstanceOne

** OpenStack deployment with Devstack
A ~vagrant up <InstanceName>~ on its first run automatically deploys
OpenStack with Devstack and then configures it for the ~--os-scope~.
It is also possible to only run the deployment of Devstack with the
following commands.

: vagrant up <InstanceName> --no-provision
: vagrant provision <InstanceName> --provision-with devstack

The ~--provision-with devstack~ refers to the Ansible
[[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/playbooks/devstack.yml][playbooks/devstack.yml]] playbook. In brief, this playbook:
1. Adds a stack user.
2. Clones Devstack stable/rocky.
3. Generates a local.conf.
4. Runs Devstack deployment.

If something goes wrong during the execution of this playbook, this is
OK to rerun the ~vagrant provision <InstanceName> --provision-with
devstack~, since the Ansible is idempotent.

** Scope interpretation
In the same manner of the previous section, it is also possible to
only run the configurations of one OpenStack instance to interpret the
~--os-scope~ with the next command.

: vagrant provision <InstanceName> --provision-with ha-scope

The ~--provision-with ha-scope~ refers to the Ansible
[[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/playbooks/ha-scope.yml][playbooks/ha-scope.yml]] playbook. In brief, this playbook:
1. Computes the list of services as explained in the "How it works"
   (see, [[#generating-the-haproxy-configuration-file][Generating the HAProxy configuration file]]).
2. Uses that list to generate the HAProxy configuration file, and then
   deploys HAProxy.
3. Installs a new plugin for python-openstackclient that adds the
   ~--os-scope~ in the CLI.
4. Ensures that HTTP requests of OpenStack services go through the
   proxy (on that particular point, read the subsection below).

*** ~[HACK]~ tag in the code
Devstack doesn't provide HAProxy deployment by default and we want to
avoid the modification of Devstack -- or any other OpenStack services
-- as much as possible. Thus, we deployed HAProxy after Devstack and
then ensure each request to OpenStack goes through the proxy thanks to
the ~HTTP_PROXY~ environment variable. This is referenced in the
current code with the ~[HACK]~ tag. In a real-world deployment (a la
Kolla), services are already hidden behind HAProxy and thus code
marked with the ~[HACK]~ tag should be removed.

* List of TODOs
- [ ] Remove the [[https://github.com/BeyondTheClouds/openstackoid/blob/665bb991f3b5a2b47f2b1073cab1e6ae4ea1d339/playbooks/haproxy/lua/interpret_scope.lua.j2#L23][forced link to Keystone of InstanceOne]].

* Misc
** See HAProxy log
Run HAProxy from the terminal
: sudo systemctl stop haproxy
: sudo vim +6 /etc/haproxy/haproxy.cfg # comment chroot and daemon line
: sudo LUA_PATH="/etc/haproxy/lua/?.lua;" haproxy -f /etc/haproxy/haproxy.cfg
: http_proxy="http://192.168.141.245:8888" curl http://10.0.2.15:9696/v2.0/networks

* Acknowledgment
[[https://twitter.com/tcarrez/status/1061665184530481152][OpenStack Berlin Hackathon]], Team 5
