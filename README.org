#+TITLE: OpenStackoÃ¯d

/Make your OpenStacks Collaborative/

This PoC aims at making several independent OpenStack instances
collaborative. The main idea consists in extending the OpenStack CLI
to define the collaboration process. A dedicated option, called
~--scope~, specifies which services (e.g., compute, image, identity,
...) of which OpenStack instance (e.g., InstanceOne, InstanceTwo, ...)
the OpenStack CLI invokes to perform the CLI request. For instance,
the provisioning of a VM in InstanceOne with an image in InstanceTwo
looks like as follows:

#+BEGIN_SRC sh
openstack server create my-vm --flavor m1.tiny --image cirros \
  --scope '{"compute": "InstanceOne", "image": "InstanceTwo"}'
#+END_SRC

This approach enables the segregation of the infrastructure into
distinct areas. It removes the relying on a single control plane and
thus, resolves network partitioning and scalability challenges in most
cases.

To get more insight, read the [[#how-it-works][how it works]] section or [[#try-it][try it]] by
yourself.
# Also read our [[https://beyondtheclouds.github.io/blog/][blog post]]


* Table of Contents                                                  :TOC@2@gh:
- [[#try-it][Try it]]
- [[#how-it-works][How it works]]
  - [[#generating-the-haproxy-configuration][Generating the HAProxy configuration]]
  - [[#scope-should-follow-the-workflow][Scope should follow the workflow]]
  - [[#resources-access-limitation][Resources access limitation]]
  - [[#the-hack-tag-in-source-code][The ~HACK~ tag in source code.]]
- [[#setup][Setup]]
- [[#list-of-todos][List of TODOs]]
- [[#misc][Misc]]
  - [[#see-haproxy-log][See HAProxy log]]
- [[#acknowledgment][Acknowledgment]]

* Try it
  :PROPERTIES:
  :CUSTOM_ID: try-it
  :END:
Get the code with a git clone.
: git clone git@github.com:BeyondTheClouds/openstackoid.git -b stable/rocky --depth 1

Then starts the two OpenStack instances (require tmux and Vagrant).
: cd openstackoid; ./setup-env.sh

The previous command starts two tmux windows and launches two
OpenStack instances, each in a virtual machine, thanks to Vagrant.
After 15 to 20 minutes, the time for Devstack to deploy the two
OpenStack instances, the output may look like the following. The top
window connects to OpenStack ~InstanceOne~ and the bottom one to
~InstanceTwo~. These two instances are completely independent and
shared no services.

#+begin_example
stack@InstanceOne:~$
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$
#+end_example

From there you can issue a standard ~openstack~ command, such as
~openstack image list~. Note the difference of ~ID~.

#+begin_example
stack@InstanceOne:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 440263d5-20a7-432b-b0db-693787bd2579 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 45da7b62-163c-4c78-aac7-363cbf4627a4 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
#+end_example

Moreover, you can use the ~--scope~ option that tells OpenStack of a
specific instance to do something by using a service from another
instance. For example, you can tell to the ~InstanceOne~ to start a VM
by using the ~image~ service from ~InstanceTwo~ (the ~ID~ of ~image~
is the one of ~InstanceTwo~). In the scope, a service is implicitly
bound to the local instance, which prevents to explicitly specify all
services.

#+begin_example
stack@InstanceOne:~$ openstack server create my-vm \
  --scope '{"image": "InstanceTwo"}' \
  --image 45da7b62-163c-4c78-aac7-363cbf4627a4 \
  --flavor m1.tiny \
  --wait
+-------------------------------------+-----------------------------------------------------------------+
| Field                               | Value                                                           |
+-------------------------------------+-----------------------------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                                                          |
| ...                                 | ...                                                             |
| image                               | cirros-0.3.5-x86_64-disk (45da7b62-163c-4c78-aac7-363cbf4627a4) |
| name                                | my-vm                                                           |
| ...                                 | ...                                                             |
| status                              | ACTIVE                                                          |
| user_id                             | 2d9440f8a4d546c88d1f5b661dc6e69b                                |
+-------------------------------------+-----------------------------------------------------------------+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 45da7b62-163c-4c78-aac7-363cbf4627a4 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
#+end_example

ðŸŽ‰

* How it works
  :PROPERTIES:
  :CUSTOM_ID: how-it-works
  :END:
In brief, every OpenStack instance comes with a proxy (here HAProxy)
in front of it. In such deployment, a service (e.g., Glance API of
~InstanceOne~) is available via two addresses:
- The /Backend/ address (i.e., ~10.0.2.15/image~) that directly
  targets Glance API.
- The /Frontend/ address (i.e., ~192.168.141.245:8888/image~)
  that targets HAProxy. HAProxy then evaluates the request and, in
  most cases, forwards it to the Backend.

Here, we add a new capability to HAProxy [[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/playbooks/haproxy/lua/interpret_scope.lua.j2][that interprets]] the
~--scope~. Instead of forwarding the request to the local Backend,
HAProxy determines the instance of the targeted service from the scope
and URL. It then forwards the request to the local Backend only if the
current instance is equivalent to the determined one. Otherwise, it
forwards the request to the Frontend of the determined instance.

As an example, here is a sample of the HAProxy configuration on
~InstanceOne~ for the ~image~ service.

#+begin_src conf-space -n
listen http-proxy
  bind 192.168.141.245:8888           # (ref:local-front)
  http-request del-header X-Forwarded-Proto if { ssl_fc }
  use_backend %[lua.interpret_scope]  # (ref:lua-scope)

# Target concrete backend
backend InstanceOne_image_public
  server InstanceOne 10.0.2.15:80 check inter 2000 rise 2 fall 5 # (ref:local-back)

# Target HA of OS instance named InstanceTwo
backend InstanceTwo_image_public
  http-request set-header Host 192.168.141.245:8888
  server InstanceTwo 192.168.142.245:8888 check inter 2000 rise 2 fall 5 # (ref:remote-front)

# Do the same for compute, identity, ...
#+end_src

The ~lua.interpret_scope~ line [[(lua-scope)]] determines the name of the
backend based on the ~--scope '{"image": "InstanceTwo"}~ and URL of
the targeted service. From there, it forwards the request whether to
the local Backend ~10.0.2.15~ (l. [[(local-back)]]) or Frontend of the
remote instance ~192.168.142.245~ (l. [[(remote-front)]]).

** Generating the HAProxy configuration
Based on a short description list of all services (see lst.
[[lst:services-desc]]), it is easy to [[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/playbooks/haproxy/haproxy.cfg.j2][generate the HAProxy configuration
file]] automatically. The description list, on the other hand, partially
comes with the next OpenStack command. The addresses of the Frontend
and Backend for all services still have to be added.

: openstack endpoint list --format json \
:   -c "Service Type" -c "Interface" -c "URL" -c "Region"

#+NAME: lst:services-desc
#+CAPTION: Services description list
#+begin_src json
{ "services" :
  [
    {
      "Service Type": "image",
      "Interface": "public",
      "URL": "192.168.141.245:8888/image",
      "Region": "InstanceOne",
      "Frontend": "192.168.141.245:8888",
      "Backend": "10.0.2.15:80"
    },
    ...
    {
      "Service Type": "image",
      "Interface": "public",
      "URL": "192.168.142.245:8888/image",
      "Region": "InstanceTwo",
      "Frontend": "192.168.142.245:8888",
      "Backend": "10.0.2.15:80"
    },
    ...
  ]
}
#+end_src

** Scope should follow the workflow
HAProxy determines from the ~--scope~ the address of the targeted
service. Which means, the scope has to be defined for every request
and subsequent requests. For instance, when Alice does an ~openstack
server create --scope ...~, the value of the ~--scope~ should not only
be attached to the initial ~POST /servers~ request made by the CLI.
But also, to all subsequent requests of the workflow, including Nova
request to Keystone to check Alice credentials, Nova request to Glance
to check/get the image. Glance request to Keystone to check Alice
credentials ...

A first solution is to modify the OpenStack code of all services to
ensure that, e.g., when Alice contacts Nova with a specific ~--scope~,
then Nova propagates that ~--scope~ in the subsequent requests.
However, in OpenStackoid, we want to avoid as much as possible
modifications to the vanilla code.

Another naive implementation would try to implement the scope
propagation at HAProxy level -- and keep OpenStack code as it is.
Unfortunately, this doesn't work since HAPrxoy is unlikely to figure
out that, e.g., the current request from Nova to Glance comes from a
previous request from Alice to Nova with a specific ~--scope~.

Luckily, every OpenStack service already propagates information from
one service to another during the entire workflow of command: the
Keystone ~X-Auth-Token~ that contains Alice credentials. Here we reuse
that information to piggyback the ~--scope~. Then, HAProxy seeks for
the ~X-Auth-Token~, extracts the scope and finally interprets it to
forwards the request to the good instance.

** TODO Resources access limitation
- Same project id
- Same keystone credential
- Resource of another instance should be accessible from the first one
  (e.g., image is OK, network is NOK).

** TODO The ~HACK~ tag in source code.
- Devstack doesn't provide HAProxy deployment
- We deployed HAProxy after Devstack and then ensure every request to
  OpenStack goes through OpenStack with ~HTTP_PROXY~.
- This is referenced in the code with the ~[HACK]~.
- In a real-world deployment (a la Kolla), services are already hidden
  behind HAProxy and thus ~[HACK]~ source code should be removed.

* Setup
# The setup is based on two runs of virtualbox-based enos deployement.
# We are going to deploy, using enos, two distinct All-in-One OpenStack
# instances. We'll then change their Haproxy configurations to make
# these two OpenStacks collaborative by interpreting the scope.

# First, clone the project:
# : git clone git@github.com:BeyondTheClouds/openstackoid.git -b stable/queens

# ** Deployment of the first instance (i.e., RegionOne)
# Setup a vanilla OpenStack with enos.

# #+BEGIN_SRC sh
# cd RegionOne
# enos deploy -f ./regionOne.yaml -e EnvRegionOne
# source EnvRegionOne/admin-openrc
# #+END_SRC

# At that point, you've got a fully operational stable/queens OpenStack
# deployed with kolla-ansible. You can do an ~openstack endpoint list~
# for instance. Then, generate HAProxy configuration files as explained
# in section [[#sec:ha-confs]].

# Afterwards, tell enos to reconfigure OpenStack with the new
# configuration, to take it into account.

# : enos os --reconfigure --tags haproxy --env EnvRegionOne

# Kill haproxy. Kolla/haproxy container is built without the support of
# lua and we need it to interpret the scope.

# : vagrant ssh
# : sudo su
# : docker stop haproxy

# Because of the kill of haproxy, keepalived unbinds its VIP. So, we
# have to set it manually.

# : ip addr add 192.168.142.244/32 dev eth2

# Finally, install a version of HAProxy that interpret lua and run it.

# : apt install haproxy -y
# : cd /etc/kolla/haproxyoid
# : haproxy -f haproxy.cfg

# ** Deployment of the second instance (i.e., RegionTwo)
# Same as the [[*Deployment of the first instance (i.e., RegionOne)][deployment of RegionOne]], but with RegionTwo.

# #+BEGIN_SRC sh
# cd RegionTwo
# enos deploy -f ./regionTwo.yaml -e EnvRegionTwo
# source EnvRegionOne/admin-openrc
# # TODO: Generate haproxy configuration files...
# enos os --reconfigure --tags haproxy --env EnvRegionOne
# vagrant ssh
# sudo su
# docker stop haproxy
# # Wait few seconds, ..
# ip addr add 192.168.144.244/32 dev eth2
# apt install haproxy -y
# cd /etc/kolla/haproxyoid
# haproxy -f haproxy.cfg
# #+END_SRC

# ** Generate HAProxy configuration files
# :PROPERTIES:
# :CUSTOM_ID: sec:ha-confs
# :END:
# First, generate the [[file:RegionOne/patches/haproxy/services.json][services.json]] file that lists all the endpoints of
# all your OpenStack instances. To make this file, run the following
# command on all OpenStack instances and concatenate the results.

# #+BEGIN_SRC sh
# openstack endpoint list \
#   -f json \
#   -c "Region" -c "Service Type" -c "Interface" -c "URL"
# #+END_SRC

# URLs have to be cleaned a little bit. Remove the protocol part (e.g.,
# ~http://~) and placeholders for values (e.g., ~%(tenant_id)s~).

# Then get the generated haproxy configuration file of the first OS
# instance.

# #+BEGIN_SRC sh
# scp -i .vagrant/machines/enos-0/virtualbox/private_key \
#     -P 2222 \
#     root@127.0.0.1:/etc/kolla/haproxy/haproxy.cfg .
# #+END_SRC

# And rewrite it so that ~keystone_internal~, ~keystone_admin~,
# ~glance_api~, ~nova_api~, ~placement_api~ and ~neutron_server~ call
# the scope-interpret sample fetch. For instance, with
# ~keystone_internal~ of RegionOne.

# #+BEGIN_SRC conf
# listen keystone_internal
#   bind 192.168.142.244:5000
#   http-request del-header X-Forwarded-Proto if { ssl_fc }
#   use_backend %[lua.scope-interpret]

# backend RegionOne_identity_public
#   server enos-r1 192.168.142.245:5000 check inter 2000 rise 2 fall 5
# backend RegionOne_identity_internal
#   server enos-r1 192.168.142.245:5000 check inter 2000 rise 2 fall 5
# backend RegionTwo_identity_public
#   http-request set-header Host 192.168.144.244:5000
#   server enos-r2 192.168.144.244:5000 check inter 2000 rise 2 fall 5
# backend RegionTwo_identity_internal
#   http-request set-header Host 192.168.144.244:5000
#   server enos-r2 192.168.144.244:5000 check inter 2000 rise 2 fall 5
# #+END_SRC

# Backend name is generated based on fields "Region", "Service Type" and
# "Interface" of [[file:RegionOne/patches/haproxy/services.json][services.json]]. Servers of the current region link to
# the concrete backend (e.g., ~192.168.142.245:5000~). Servers of other
# regions link to HAProxy of other regions (e.g.,
# ~192.168.144.244:5000~, as in "URL" of [[file:RegionOne/patches/haproxy/services.json][services.json]]).

# ** Change openstack CLI to get the scope
# Install the following cli that interpret the ~--scope~:
# #+BEGIN_SRC sh
# git clone git@github.com:BeyondTheClouds/python-openstackclient.git -b openstackoid/queens
# pip install -e python-openstackclient
# #+END_SRC

# ** [HACK] tag

* List of TODOs
- [ ] Remove the [[https://github.com/BeyondTheClouds/openstackoid/blob/665bb991f3b5a2b47f2b1073cab1e6ae4ea1d339/playbooks/haproxy/lua/interpret_scope.lua.j2#L23][forced link to Keystone of InstanceOne]].

* Misc
** See HAProxy log
Run HAProxy from the terminal
: sudo systemctl stop haproxy
: sudo vim +6 /etc/haproxy/haproxy.cfg # comment chroot and daemon line
: sudo LUA_PATH="/etc/haproxy/lua/?.lua;" haproxy -f /etc/haproxy/haproxy.cfg
: http_proxy="http://192.168.141.245:8888" curl http://10.0.2.15:9696/v2.0/networks

* Acknowledgment
[[https://twitter.com/tcarrez/status/1061665184530481152][OpenStack Berlin Hackathon]], Team 5
