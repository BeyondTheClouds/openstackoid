#+TITLE: OpenStackoÃ¯d

/Make your OpenStacks Collaborative/

This PoC aims at making several independent OpenStack instances
collaborative. The main idea consists in extending the OpenStack CLI
to define the collaboration process. Through a dedicated option
(called ~--scope~), the DevOps specifies which services (e.g.,
compute, image, identity, ...) of which OpenStack instance (e.g.,
InstanceOne, InstanceTwo, ...) should be invoked to perform the CLI
request. For instance, the provisioning of a VM in InstanceOne with an
image in InstanceTwo looks like as follows:

#+BEGIN_SRC sh
openstack server create my-vm --flavor m1.tiny --image cirros \
  --scope '{"compute": "InstanceOne", "image": "InstanceTwo"}'
#+END_SRC

This approach removes the relying on a single control plane and
enables the segregation of the infrastructure into distinct areas
resolving network partitioning and scalability challenges in most
cases.

To get more on the principle, read our [[https://beyondtheclouds.github.io/blog/][blog post]] or the [[#how-it-works][how it works
section]] below.

* Try it
Get the code with
: git clone git@github.com:BeyondTheClouds/openstackoid.git -b stable/rocky --depth 1

Then starts the two OpenStack instances (require tmux and Vagrant).
: cd openstackoid; ./setup-env.sh

The previous command starts two tmux windows and launches two
OpenStack instances, each in a virtual machine, thanks to Vagrant.
After 15 to 20 minutes, the time for Devstack to deploy the two
OpenStack instances, the output may look like the following. The top
window is connected to OpenStack ~InstanceOne~ and the bottom one to
~InstanceTwo~. These two instances are completely independent and
shared no services.

#+begin_example
stack@InstanceOne:~$
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$
#+end_example

From there you can issue normal ~openstack~ command, such as
~openstack image list~. Note the difference of ~ID~.

#+begin_example
stack@InstanceOne:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 440263d5-20a7-432b-b0db-693787bd2579 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 45da7b62-163c-4c78-aac7-363cbf4627a4 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
#+end_example

But, you can also use the ~--scope~ option that tells to OpenStack of
a specific instance to use a service from another instance. For
example, start a VM in ~InstanceOne~ by using an image from
~InstanceTwo~ (the ~ID~ of ~image~ is the one of ~InstanceTwo~).

#+begin_example
stack@InstanceOne:~$ openstack server create my-vm \
  --scope '{"image": "InstanceTwo"}' \
  --image 45da7b62-163c-4c78-aac7-363cbf4627a4 \
  --flavor m1.tiny \
  --wait
+-------------------------------------+-----------------------------------------------------------------+
| Field                               | Value                                                           |
+-------------------------------------+-----------------------------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                                                          |
| ...                                 | ...                                                             |
| image                               | cirros-0.3.5-x86_64-disk (45da7b62-163c-4c78-aac7-363cbf4627a4) |
| name                                | my-vm                                                           |
| ...                                 | ...                                                             |
| status                              | ACTIVE                                                          |
| user_id                             | 2d9440f8a4d546c88d1f5b661dc6e69b                                |
+-------------------------------------+-----------------------------------------------------------------+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stack@InstanceTwo:~$ openstack image list
+--------------------------------------+--------------------------+--------+
| ID                                   | Name                     | Status |
+--------------------------------------+--------------------------+--------+
| 45da7b62-163c-4c78-aac7-363cbf4627a4 | cirros-0.3.5-x86_64-disk | active |
+--------------------------------------+--------------------------+--------+
#+end_example

ðŸŽ‰

* How it works
In brief, a proxy (here HAProxy) is started in front of every
OpenStack instance. Hence, a service such as Nova API of ~InstanceOne~
is available through a request to two addresses:
- The /Backend/ address (i.e., ~10.0.2.15/v2.1/compute~) that directly
  targets Nova API.
- The /Frontend/ address (i.e., ~192.168.141.245:8888/v2.1/compute~)
  that targets HAProxy. HAProxy then evaluates the request and, in
  most of the case, forwards it to the /Backend/.

But here, we add the capability to HAProxy [[https://github.com/BeyondTheClouds/openstackoid/blob/stable/rocky/playbooks/haproxy/lua/interpret_scope.lua.j2][to interpret]] the ~--scope~.
That is to say, instead of forwarding the request to the /Backend/ of
~InstanceOne~, HAProxy forwards it to the /Backend/ of the instance
referenced in the scope.

** Scope follows the workflow
The scope tells HAProxy to which instance it is supposed to forward
the request. The scope thus has to be defined for every request. To be
more specific, when Alice does a ~openstack server create --scope
$SCOPE ...~, the ~$SCOPE~ should not only be attached to the initial
~POST /servers~ request made by the CLI. But also, to all subsequent
request of the workflow, including Nova request to Keystone to check
Alice credentials, Nova request to Glance to check/get the image.
Glance request to Keystone to check Alice credentials ...

A first solution would be to modify the OpenStack code of services to
ensure that, e.g., when Alice contacts Nova with the ~$SCOPE~, then
Nova propagates the ~$SCOPE~ when it contacts Glance. But, in
OpenStackoid we want to avoid, as much as possible, modifications to
vanilla code.

Another, naive implementation will try to implement the scope
propagation at HAProxy level -- and keep OpenStack code as it is.
Unfortunately, this doesn't work since HAPrxoy is unlikely to figure
out that, e.g., the current request from Nova to Glance actually comes
from a former request from Alice to Nova with the ~$SCOPE~.

Luckily, OpenStack service already propagates an information from one
service to another during the entire workflow of a command: the
Keystone ~X-Auth-Token~ that contains Alice credentials. Here we reuse
that information and piggyback the ~$SCOPE~. Then, HAProxy seeks for
the ~X-Auth-Token~, extracts the scope and finally interprets it to
forwards the request to the good instance.

** TODO Resources access
- Same project id
- Same keystone credential
- Resource of another instance should be accessible from the first one
  (e.g., image is OK, network is NOK).

** TODO The [HACK] tag in source code.
- Devstack doesn't provide HAProxy deployment
- We deployed HAProxy after devstack and then ensure every request to
  OpenStack goes through OpenStack with ~HTTP_PROXY~.
- This is referenced in the code with the ~[HACK]~.
- In an real world deployment (a la kolla), services are already hides
  behind HAProxy and thus ~[HACK]~ source code should be removed.

* Setup

** TODO HAProxy configuration
   #+begin_src json
{ "services" :
  [
    {
      "Service Type": "identity",
      "Interface": "admin",
      "URL": "192.168.141.245:8888/identity",
      "Region": "InstanceOne",
      "Frontend": "192.168.141.245:8888",
      "Backend": "10.0.2.15:80"
    },
    ...
    {
      "Service Type": "network",
      "Interface": "public",
      "URL": "192.168.142.245:9696",
      "Region": "InstanceTwo",
      "Frontend": "192.168.142.245:8888",
      "Backend": "10.0.2.15:9696"
    }
  ]
}

   #+end_src

# The setup is based on two runs of virtualbox-based enos deployement.
# We are going to deploy, using enos, two distinct All-in-One OpenStack
# instances. We'll then change their Haproxy configurations to make
# these two OpenStacks collaborative by interpreting the scope.

# First, clone the project:
# : git clone git@github.com:BeyondTheClouds/openstackoid.git -b stable/queens

# ** Deployment of the first instance (i.e., RegionOne)
# Setup a vanilla OpenStack with enos.

# #+BEGIN_SRC sh
# cd RegionOne
# enos deploy -f ./regionOne.yaml -e EnvRegionOne
# source EnvRegionOne/admin-openrc
# #+END_SRC

# At that point, you've got a fully operational stable/queens OpenStack
# deployed with kolla-ansible. You can do an ~openstack endpoint list~
# for instance. Then, generate HAProxy configuration files as explained
# in section [[#sec:ha-confs]].

# Afterwards, tell enos to reconfigure OpenStack with the new
# configuration, to take it into account.

# : enos os --reconfigure --tags haproxy --env EnvRegionOne

# Kill haproxy. Kolla/haproxy container is built without the support of
# lua and we need it to interpret the scope.

# : vagrant ssh
# : sudo su
# : docker stop haproxy

# Because of the kill of haproxy, keepalived unbinds its VIP. So, we
# have to set it manually.

# : ip addr add 192.168.142.244/32 dev eth2

# Finally, install a version of HAProxy that interpret lua and run it.

# : apt install haproxy -y
# : cd /etc/kolla/haproxyoid
# : haproxy -f haproxy.cfg

# ** Deployment of the second instance (i.e., RegionTwo)
# Same as the [[*Deployment of the first instance (i.e., RegionOne)][deployment of RegionOne]], but with RegionTwo.

# #+BEGIN_SRC sh
# cd RegionTwo
# enos deploy -f ./regionTwo.yaml -e EnvRegionTwo
# source EnvRegionOne/admin-openrc
# # TODO: Generate haproxy configuration files...
# enos os --reconfigure --tags haproxy --env EnvRegionOne
# vagrant ssh
# sudo su
# docker stop haproxy
# # Wait few seconds, ..
# ip addr add 192.168.144.244/32 dev eth2
# apt install haproxy -y
# cd /etc/kolla/haproxyoid
# haproxy -f haproxy.cfg
# #+END_SRC

# ** Generate HAProxy configuration files
# :PROPERTIES:
# :CUSTOM_ID: sec:ha-confs
# :END:
# First, generate the [[file:RegionOne/patches/haproxy/services.json][services.json]] file that lists all the endpoints of
# all your OpenStack instances. To make this file, run the following
# command on all OpenStack instances and concatenate the results.

# #+BEGIN_SRC sh
# openstack endpoint list \
#   -f json \
#   -c "Region" -c "Service Type" -c "Interface" -c "URL"
# #+END_SRC

# URLs have to be cleaned a little bit. Remove the protocol part (e.g.,
# ~http://~) and placeholders for values (e.g., ~%(tenant_id)s~).

# Then get the generated haproxy configuration file of the first OS
# instance.

# #+BEGIN_SRC sh
# scp -i .vagrant/machines/enos-0/virtualbox/private_key \
#     -P 2222 \
#     root@127.0.0.1:/etc/kolla/haproxy/haproxy.cfg .
# #+END_SRC

# And rewrite it so that ~keystone_internal~, ~keystone_admin~,
# ~glance_api~, ~nova_api~, ~placement_api~ and ~neutron_server~ call
# the scope-interpret sample fetch. For instance, with
# ~keystone_internal~ of RegionOne.

# #+BEGIN_SRC conf
# listen keystone_internal
#   bind 192.168.142.244:5000
#   http-request del-header X-Forwarded-Proto if { ssl_fc }
#   use_backend %[lua.scope-interpret]

# backend RegionOne_identity_public
#   server enos-r1 192.168.142.245:5000 check inter 2000 rise 2 fall 5
# backend RegionOne_identity_internal
#   server enos-r1 192.168.142.245:5000 check inter 2000 rise 2 fall 5
# backend RegionTwo_identity_public
#   http-request set-header Host 192.168.144.244:5000
#   server enos-r2 192.168.144.244:5000 check inter 2000 rise 2 fall 5
# backend RegionTwo_identity_internal
#   http-request set-header Host 192.168.144.244:5000
#   server enos-r2 192.168.144.244:5000 check inter 2000 rise 2 fall 5
# #+END_SRC

# Backend name is generated based on fields "Region", "Service Type" and
# "Interface" of [[file:RegionOne/patches/haproxy/services.json][services.json]]. Servers of the current region link to
# the concrete backend (e.g., ~192.168.142.245:5000~). Servers of other
# regions link to HAProxy of other regions (e.g.,
# ~192.168.144.244:5000~, as in "URL" of [[file:RegionOne/patches/haproxy/services.json][services.json]]).

# ** Change openstack CLI to get the scope
# Install the following cli that interpret the ~--scope~:
# #+BEGIN_SRC sh
# git clone git@github.com:BeyondTheClouds/python-openstackclient.git -b openstackoid/queens
# pip install -e python-openstackclient
# #+END_SRC

# ** [HACK] tag

* TODO List
- [ ] Remove the [[https://github.com/BeyondTheClouds/openstackoid/blob/665bb991f3b5a2b47f2b1073cab1e6ae4ea1d339/playbooks/haproxy/lua/interpret_scope.lua.j2#L23][forced link to Keystone of InstanceOne]].

* Misc
** See HAProxy log
Run HAProxy from the terminal
: sudo systemctl stop haproxy
: sudo vim +6 /etc/haproxy/haproxy.cfg # comment chroot and daemon line
: sudo LUA_PATH="/etc/haproxy/lua/?.lua;" haproxy -f /etc/haproxy/haproxy.cfg
: http_proxy="http://192.168.141.245:8888" curl http://10.0.2.15:9696/v2.0/networks

* Acknowledgment
[[https://twitter.com/tcarrez/status/1061665184530481152][OpenStack Berlin Hackathon]], Team 5
